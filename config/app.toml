# Application configuration for bomdia

[model]
dia_checkpoint = "nari-labs/Dia-1.6B-0626"
dia_checkpoint_revision = "main"
# Optional: Specify the compute precision "float16", "float32", "bfloat16"
# Defaults will use automatic detection.
dia_compute_dtype = "float32"
# Optional: Specify the compute device. Options: "auto", "cuda", "mps", "cpu".
# Defaults to "auto" for automatic detection.
# device = "cpu"

# LiteLLM model string (e.g., "openai/gpt-4o-mini", "ollama/llama3", "claude-3-haiku-20240307")
llm_spec = "cerebras/llama-4-scout-17b-16e-instruct"

[model.dia_generate_params]
# Uncomment and set any of the following parameters to override the DiaTTS
# model's internal defaults. Only the parameters you provide will be used.
# cfg_scale = 3.0
# temperature = 1.2
temperature = 1.6
# top_p = 0.95
# cfg_filter_top_k = 45
# max_tokens = 3072
# use_torch_compile = false

[model.parameters]
temperature = 1
max_tokens = 4096

[pipeline]
context_window = 2
pause_placeholder = "[insert-verbal-tag-for-pause]"
max_tag_rate = 0.25
avg_wps = 2.875
# Optionally define a seed for specific voice pair and genation characteristics
# seed = 12345
# fully_deterministic = False
# min_chunk_duration = 5.0
# max_chunk_duration = 10.0
# Whether to generate synthetic voice prompts for unprompted speakers (default: True)
generate_synthetic_prompts = false

[tags] # TODO - this seems to belong in prompts
verbal_tags = [
    "(laughs)",
    "(clears throat)",
    "(sighs)",
    "(gasps)",
    "(coughs)",
    "(singing)",
    "(sings)",
    "(mumbles)",
    "(beep)",
    "(groans)",
    "(sniffs)",
    "(claps)",
    "(screams)",
    "(inhales)",
    "(exhales)",
    "(applause)",
    "(burps)",
    "(humming)",
    "(sneezes)",
    "(chuckle)",
    "(whistles)",
]

line_combiners = [
    "…um,",
    "- uh -",
    "— hmm —",
]

[director_agent.rate_control]
# The target ratio of lines that should receive a new verbal tag (e.g., 0.10 for 10%).
target_tag_rate = 0.16
# The maximum number of "burst" tags the agent can inject above its target rate.
# This allows it to handle emotionally dense scenes.
tag_burst_allowance = 3

[director_agent.review]
# Mode for the Director's final review.
# "procedural": Fast, rule-based tag pruning (default).
# "llm": Slower, higher-quality LLM-based curation.
mode = "llm"

[persistence]
rehearsal_checkpoint_path = "rehearsal_checkpoints.sqlite"

# Configuration for synthetic voice prompt generation
[generate_prompt]
# Directory where synthetic voice prompts are saved
output_dir = "synthetic_prompts"

[audio]
output_format = "flac"
sampling_rate = 44100
sample_width = 2
channels = 1
